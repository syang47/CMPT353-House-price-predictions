{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e410184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import re\n",
    "\n",
    "def read_data():\n",
    "    listings_data = pd.read_csv('listings.csv.gz')\n",
    "    amenities_data = pd.read_json('amenities-vancouver.json.gz', lines=True)\n",
    "    user_input1 = pd.read_csv('input1.txt', sep=':\\s', names=['Preference','Preference_Data'], engine='python')\n",
    "    \n",
    "    return listings_data, amenities_data, user_input1\n",
    "\n",
    "\n",
    "def clean_amenities_data(amenities_data, amenities_required):\n",
    "\n",
    "    #find unique amenities and the number of them to choose which are important for a traveller\n",
    "    # print(amenities_data['amenity'].value_counts())\n",
    "\n",
    "    #adapted from : https://www.kite.com/python/answers/how-to-filter-a-pandas-dataframe-with-a-list-by-%60in%60-or-%60not-in%60-in-python\n",
    "    bool_series = amenities_data.amenity.isin(amenities_required)\n",
    "    filtered_amenities_df = amenities_data[bool_series]\n",
    "    filtered_amenities_df = filtered_amenities_df.drop(['timestamp','tags'], axis=1).dropna() # dropping unnecessary columns, and filter out NA values\n",
    "    filtered_amenities_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return filtered_amenities_df\n",
    "\n",
    "\n",
    "#reference: https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "def haversine_distance(df, lon2, lat2):\n",
    "    # convert decimal degrees to radians \n",
    "    lon1=np.radians(df['lon'])\n",
    "    lat1=np.radians(df['lat'])\n",
    "    lon2=np.radians(lon2)\n",
    "    lat2=np.radians(lat2)\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = (dlat/2).apply(sin)**2 + (lat1).apply(sin) * cos(lat2) * (dlon/2).apply(sin)**2\n",
    "    c = 2 * ((a).apply(sqrt).apply(asin)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r * 1000\n",
    "\n",
    "# \n",
    "\n",
    "def clean_listings_data(listings_data, accommodates_input, room_input, price_range_input, exact, amenities_data_clean):\n",
    "    #keep only the columns we need\n",
    "    columns_needed = ['id', 'listing_url', 'name', 'description', 'picture_url', 'latitude', 'longitude', 'property_type', 'accommodates', 'bedrooms', 'beds', 'amenities', 'price',  'review_scores_value']\n",
    "    listings_data = listings_data[columns_needed].copy()\n",
    "    listings_data['price'] = listings_data['price'].apply(lambda x: x.replace(',','').replace('$','')).astype(float)\n",
    "    \n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "    # extract price_range from string\n",
    "    p_range = [float(s) for s in re.findall('[0-9]+', price_range_input)]\n",
    "    min_price = p_range[0]\n",
    "    max_price = p_range[1]\n",
    "    \n",
    "    bedrooms=listings_data['bedrooms']\n",
    "    accommodates=listings_data['accommodates']\n",
    "    \n",
    "    # if user is fine with referencing their input as minimum requirements -> if not exact\n",
    "    # if user wants exact filter -> else \n",
    "    \n",
    "    if not exact:\n",
    "        # find listing data with bedrooms >= room_input and accommodates >= accomodates_input\n",
    "        listings_data = listings_data[(bedrooms >= room_input) & (accommodates >= accommodates_input)]\n",
    "        listings_data = listings_data[(listings_data['price'] <= max_price) & (listings_data['price'] >= min_price)]\n",
    "    else:\n",
    "        # find listing data with bedrooms == room_input and accommodates == accomodates_input\n",
    "        listings_data = listings_data[(bedrooms == room_input) & (accommodates == accommodates_input)].reset_index(drop=True)\n",
    "        listings_data = listings_data[(listings_data['price'] <= max_price) & (listings_data['price'] >= min_price)]\n",
    "    \n",
    "    # if listings_data is empty\n",
    "    if listings_data.empty:\n",
    "        print(\"Cannot find any listings with current filter, please try with other filters.\\n\")\n",
    "        return   \n",
    "    #add a column for number of amenities nearby to each listing\n",
    "    listings_data['num_amenities_nearby'] = listings_data.apply(lambda x: num_amenities(x['latitude'], x['longitude'], amenities_data_clean), axis = 1)\n",
    "\n",
    "    #add a column 'amenities_score' based on the number of different amenities nearby\n",
    "    listings_data['amenities_score'] = listings_data['num_amenities_nearby'].apply(lambda x : ameneties_score(x))\n",
    "    \n",
    "    listings_data=listings_data.reset_index(drop=True)\n",
    "    \n",
    "    return listings_data\n",
    "\n",
    "\n",
    "# return a dictionary with number of amenities in a 1km radius of this lat and lon\n",
    "def num_amenities(lat, lon, amenities_data_clean):\n",
    "    distance = haversine_distance(amenities_data_clean, lon, lat)\n",
    "    amenities_data_clean['distance'] = distance\n",
    "    data_withinR = amenities_data_clean.loc[amenities_data_clean['distance'] < 1000].reset_index(drop=True)\n",
    "    amenities_series = data_withinR.pivot_table(columns = ['amenity'], aggfunc='size')  # Counts # of amenities, type=pd.series\n",
    "    amenities_dict = amenities_series.to_dict()# converts series to dict\n",
    "    return amenities_dict\n",
    "    \n",
    "\n",
    "def ameneties_score(my_dict):\n",
    "    \n",
    "    num_different_amenities = len(my_dict)\n",
    "    score = num_different_amenities * 10 \n",
    "        \n",
    "    for key in my_dict:\n",
    "        if (my_dict[key] > 30):\n",
    "            score+=30\n",
    "        else:\n",
    "            score+= my_dict[key]\n",
    "    return score\n",
    "\n",
    "def find_best_listing():\n",
    "    #Read Data\n",
    "    listings_data, amenities_data = read_data()\n",
    "\n",
    "    # Change amenities here (updated the \"restaurant\" typo)\n",
    "    amenities_required = ['restaurant', 'fast_food', 'cafe','bank','atm','pharmacy','bicycle_rental','fuel','pub','bar','car_sharing','car_rental','clinic','doctors','hospital','ice_cream','fountain','theatre','police','bus_station']\n",
    "\n",
    "    # TODO:turn this into user input in the end \n",
    "    num_accomodates = 10\n",
    "    num_bedrooms = 3\n",
    "    max_price = 300 \n",
    "\n",
    "    #Data Cleaning\n",
    "    amenities_data_clean = clean_amenities_data(amenities_data, amenities_required)\n",
    "    listings_data_clean = clean_listings_data(listings_data,num_accomodates,num_bedrooms,max_price)\n",
    "\n",
    "    #add a column for number of amenities nearby to each listing\n",
    "    listings_data_clean['num_amenities_nearby'] = listings_data_clean.apply(lambda x: num_amenities(x['latitude'], x['longitude'], amenities_data_clean), axis = 1)\n",
    "\n",
    "    #add a column 'amenities_score' based on the number of different amenities nearby\n",
    "    listings_data_clean['amenities_score'] = listings_data_clean['num_amenities_nearby'].apply(lambda x : ameneties_score(x))\n",
    "\n",
    "    #sort based on amenities score\n",
    "    listings_data_clean.sort_values(['amenities_score'], ascending = [False], inplace = True)\n",
    "    print(listings_data_clean)\n",
    "\n",
    "def clean_data_ML(listings_data):\n",
    "    \n",
    "    columns_needed = ['latitude', 'longitude', 'host_response_time', 'host_response_rate', 'host_acceptance_rate','host_is_superhost','host_listings_count', 'host_total_listings_count', 'host_identity_verified','neighbourhood_cleansed', 'property_type', 'room_type', 'accommodates', 'bedrooms', 'beds', 'amenities', 'price',   'minimum_nights', 'maximum_nights', 'maximum_nights_avg_ntm',  'availability_30', 'availability_60', 'availability_90','availability_365','number_of_reviews', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin','review_scores_communication','review_scores_location','review_scores_value', 'reviews_per_month' ]\n",
    "    listings_data = listings_data[columns_needed]\n",
    "\n",
    "    # remove all rows with any Null Value\n",
    "    listings_data = listings_data.dropna(how='any',axis=0) \n",
    "\n",
    "    # find number of amenities provided by the host\n",
    "    listings_data['num_amenities'] = listings_data['amenities'].apply(lambda x: len(x)).astype('float64')\n",
    "    listings_data.drop('amenities', axis= 1, inplace = True)\n",
    "\n",
    "    #Label Encoding categorical Data\n",
    "    lb_make = LabelEncoder()\n",
    "    listings_data['host_response_time'] = lb_make.fit_transform(listings_data['host_response_time'])\n",
    "    listings_data['host_is_superhost'] = lb_make.fit_transform(listings_data['host_is_superhost'])\n",
    "    listings_data['host_identity_verified'] = lb_make.fit_transform(listings_data['host_identity_verified'])\n",
    "    listings_data['neighbourhood_cleansed'] = lb_make.fit_transform(listings_data['neighbourhood_cleansed'])\n",
    "    listings_data['property_type'] = lb_make.fit_transform(listings_data['property_type'])\n",
    "    listings_data['room_type'] = lb_make.fit_transform(listings_data['room_type'])\n",
    "\n",
    "    #convert strings to float\n",
    "    listings_data['host_response_rate'] = listings_data['host_response_rate'].apply(lambda x: float(x.replace('%','')))\n",
    "    listings_data['host_acceptance_rate'] = listings_data['host_acceptance_rate'].apply(lambda x: float(x.replace('%','')))\n",
    "    listings_data['price'] = listings_data['price'].apply(lambda x: float(x.replace('$','').replace(',','')))\n",
    "    return listings_data\n",
    "\n",
    "    \n",
    "def run_ml(listings_data_clean, amenities_data_clean):\n",
    "    \n",
    "    X = listings_data_clean.drop('price',1)\n",
    "    y = listings_data_clean['price']\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "    knn = KNeighborsRegressor(n_neighbors=50)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_sc = knn.score(X_valid, y_valid)\n",
    "    print(\"Knn Score:\", knn_sc)\n",
    "    \n",
    "    rf = RandomForestRegressor(100, max_depth=40)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_sc = rf.score(X_valid, y_valid)\n",
    "    print(\"Random Forest Score:\",rf_sc)\n",
    "    \n",
    "    gb =  GradientBoostingRegressor()\n",
    "    gb.fit(X_train, y_train)    \n",
    "    gb_sc = gb.score(X_valid, y_valid)\n",
    "    print(\"Gradient Boosting Score:\",gb_sc)\n",
    "\n",
    "    # Now we want to see if adding amenities score improves our model\n",
    "    #add a column for number of amenities nearby to each listing\n",
    "    listings_data_clean['num_amenities_nearby'] = listings_data_clean.apply(lambda x: num_amenities(x['latitude'], x['longitude'], amenities_data_clean), axis = 1)\n",
    "    \n",
    "    #add a column 'amenities_score' based on the number of different amenities nearby\n",
    "    listings_data_clean['amenities_score'] = listings_data_clean['num_amenities_nearby'].apply(lambda x : ameneties_score(x))\n",
    "    listings_data_clean = listings_data_clean.drop('num_amenities_nearby',1)\n",
    "\n",
    "    X = listings_data_clean.drop('price',1)\n",
    "    y = listings_data_clean['price']\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "\n",
    "    knn_A = KNeighborsRegressor(50)\n",
    "    knn_A.fit(X_train, y_train)\n",
    "    knn_A_sc = knn_A.score(X_valid, y_valid)\n",
    "    print(\"Knn Score with ameneties_score:\",knn_A_sc)\n",
    "\n",
    "    rf_A = RandomForestRegressor(100, max_depth=40)\n",
    "    rf_A.fit(X_train, y_train)\n",
    "    rf_A_sc = rf_A.score(X_valid, y_valid)\n",
    "    print(\"Random Forest Score with amenities_score:\",rf_A_sc)\n",
    "\n",
    "    gb_A = GradientBoostingRegressor()\n",
    "    gb_A.fit(X_train, y_train)  \n",
    "    gb_A_sc = gb_A.score(X_valid, y_valid)\n",
    "    print(\"Gradient Boosting Score with amenities_score:\",gb_A_sc)\n",
    "\n",
    "    return knn_sc, knn_A_sc, rf_sc, rf_A_sc, gb_sc, gb_A_sc\n",
    "\n",
    "# handles user's input textfile \n",
    "def handle_input(inputfile):\n",
    "    for (x) in range(len(inputfile)):\n",
    "        if inputfile['Preference'].iloc[x].lower() == \"accommodates\":\n",
    "            accommodates_input = float(inputfile['Preference_Data'].iloc[x])\n",
    "        if inputfile['Preference'].iloc[x].lower() == \"bedrooms\":\n",
    "            room_input = float(inputfile['Preference_Data'].iloc[x])\n",
    "        if inputfile['Preference'].iloc[x].lower() == \"price range\":\n",
    "            price_range_input = inputfile['Preference_Data'].iloc[x]\n",
    "        if inputfile['Preference'].iloc[x].lower() == \"exact\":\n",
    "            exact = inputfile['Preference_Data'].iloc[x]\n",
    "    if exact.lower() == \"true\":\n",
    "        exact = True\n",
    "    else:\n",
    "        exact = False\n",
    "           \n",
    "    return accommodates_input, room_input, price_range_input, exact\n",
    "\n",
    "# generates top 3 listings sorted by best review score, best amenity score, and best price\n",
    "def generate_output(listings_data_clean):\n",
    "    \n",
    "    # sort by price in ascending order\n",
    "    listings_by_price = listings_data_clean.sort_values(by=\"price\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    # sort by review_scores_values in descending order, drop na scores(?)\n",
    "    listings_by_rscore = listings_data_clean.sort_values(['review_scores_value'], ascending=False).dropna().reset_index(drop=True)\n",
    "\n",
    "    # sort by amenities_score in descending order, drop na scores(?)\n",
    "    listings_by_ascore = listings_data_clean.sort_values(['amenities_score'], ascending=False).dropna().reset_index(drop=True)\n",
    "    \n",
    "    # output lowest_price listing, highest scored listing to another dataframe\n",
    "    x = listings_by_rscore.head(1)\n",
    "    x[\"result\"] = \"Best Scored\"    \n",
    "    cols = list(x.columns)\n",
    "    cols = [cols[-1]]+cols[:-1]\n",
    "    x = x[cols]\n",
    "\n",
    "    y = listings_by_price.head(1)\n",
    "    y[\"result\"] = \"Best Valued\"\n",
    "    cols = list(y.columns)\n",
    "    cols = [cols[-1]]+cols[:-1]\n",
    "    y = y[cols]\n",
    "\n",
    "    z = listings_by_ascore.head(1)\n",
    "    z[\"result\"] = \"Best Amenity Scored\"\n",
    "    cols = list(z.columns)\n",
    "    cols = [cols[-1]]+cols[:-1]\n",
    "    z = z[cols]\n",
    "\n",
    "    sorted_output = pd.concat([z, x, y], axis=0, ignore_index=True)  \n",
    "    return sorted_output\n",
    "\n",
    "# returns amenities around the top 3 listings\n",
    "def find_amenties_around_top_listings(sorted_output, amenities_data_clean, i):\n",
    "    amen_output = amenities_data_clean.copy()\n",
    "    lon = sorted_output.iloc[i,7] # lon from utput listing \n",
    "    lat = sorted_output.iloc[i,6] # lat\n",
    "    distance = haversine_distance(amen_output, lon, lat)\n",
    "    amen_output['distance'] = distance\n",
    "    data_withinR = amen_output.loc[amen_output['distance'] < 1000].reset_index(drop=True)\n",
    "        \n",
    "    return data_withinR\n",
    "\n",
    "def main():\n",
    "    # read data\n",
    "    listings_data, amenities_data, user_input1 = read_data()\n",
    "    \n",
    "    # handle input file\n",
    "    \n",
    "    accommodates_input, room_input, price_range_input, exact = handle_input(user_input1)\n",
    "    \n",
    "\n",
    "    # clean OSM amenities data\n",
    "    amenities_required = ['restaurant', 'fast_food', 'cafe','bank','atm','pharmacy','bicycle_rental','fuel','pub','bar','car_sharing','car_rental','clinic','doctors','hospital','ice_cream','fountain','theatre','police','bus_station']\n",
    "    amenities_data_clean = clean_amenities_data(amenities_data, amenities_required)\n",
    "    print(amenities_data_clean)\n",
    "    \n",
    "    # clean AirBnb listings data\n",
    "    listings_data_clean = clean_listings_data(listings_data, accommodates_input, room_input, price_range_input, exact, amenities_data_clean)\n",
    "\n",
    "    # Perform ML Trials and store output score to df\n",
    "    [knn_sc, knn_A_sc, rf_sc, rf_A_sc, gb_sc, gb_A_sc] = run_ml(clean_data_ML(listings_data), amenities_data_clean)\n",
    "    ML_RES = [[knn_sc,knn_A_sc], \n",
    "              [rf_sc, rf_A_sc], \n",
    "              [gb_sc,gb_A_sc]]\n",
    "    ML_df = pd.DataFrame(ML_RES, \n",
    "                         columns=[\"AirBnb's Listing Info\", \"AirBnb's Listing Info with Amenity Scores\"], \n",
    "                         index=['K-Nearest Neighbors','Random Forest','Gradient Boosting'])\n",
    "    ML_df.index.name = \"Regressors Used\"\n",
    "    print(ML_df)\n",
    "\n",
    "    # sort filtered data by best review score, best amenity score, and best price\n",
    "    sorted_output = generate_output(listings_data_clean)\n",
    "\n",
    "    # outputting the filtered listings --> top 3 and total\n",
    "    TOP3_OUT = sorted_output.to_csv(\"Top3_Filtered_ABNB_Listings.csv\",na_rep='(missing)')\n",
    "    TOTAL_OUT = listings_data_clean.to_csv(\"Total_Filtered_ABNB_Listings.csv\",na_rep='(missing)')\n",
    "    \n",
    "    # outputting nearby amenities around the top 3 filtered listing\n",
    "    for i in range(len(sorted_output)):\n",
    "        if sorted_output['result'].iloc[i] == \"Best Amenity Scored\":\n",
    "            data_withinA = find_amenties_around_top_listings(sorted_output, amenities_data_clean, i)\n",
    "            data_withinA.index.name = \"Best Amenity Scored\"\n",
    "            data_withinA.to_csv('Best_Amenity_Scored_Listing_nearbyAmenities.csv',na_rep='(missing)')\n",
    "            print(\"Found the Best Amenity Scored Listing's nearby amenities\")\n",
    "\n",
    "        if sorted_output['result'].iloc[i] == \"Best Scored\":\n",
    "            data_withinS = find_amenties_around_top_listings(sorted_output, amenities_data_clean, i)\n",
    "            data_withinS.index.name = \"Best Scored\"\n",
    "            data_withinS.to_csv('Best_Reviewd_Scored_Listing_nearbyAmenities.csv',na_rep='(missing)')\n",
    "            print(\"Found the Best Review Scored Listing's nearby amenities\")\n",
    "\n",
    "        if sorted_output['result'].iloc[i] == \"Best Valued\":\n",
    "            data_withinP = find_amenties_around_top_listings(sorted_output, amenities_data_clean, i)\n",
    "            data_withinA.index.name = \"Best Valued\"\n",
    "            data_withinA.to_csv('Best_Valued_Listing_nearbyAmenities.csv',na_rep='(missing)')\n",
    "            print(\"Found the Best Valued Listing's nearby amenities\")\n",
    "\n",
    "    # outputting the ML prediction results\n",
    "    ML_OUT = ML_df.to_csv(\"ML_Price_Prediction.csv\",na_rep='(missing)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0235d7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lat         lon     amenity                      name\n",
      "0     49.260812 -123.125736        cafe                 Starbucks\n",
      "1     49.260953 -123.125704   fast_food                Salad Loop\n",
      "2     49.264041 -123.153407        fuel                     Shell\n",
      "3     49.126650 -123.182470  restaurant  Best Bite Indian Cuisine\n",
      "4     49.283192 -123.109050         pub                The Cambie\n",
      "...         ...         ...         ...                       ...\n",
      "6561  49.250408 -123.076261  restaurant            House of Dosas\n",
      "6562  49.278424 -122.806704        cafe          Creekside Coffee\n",
      "6563  49.278770 -122.797628  restaurant                Togo Sushi\n",
      "6564  49.282666 -122.826978         pub      Brown's Social House\n",
      "6565  49.282420 -122.826340        cafe          Gallagher's Cafe\n",
      "\n",
      "[6566 rows x 4 columns]\n",
      "Knn Score: 0.037784108119645055\n",
      "Random Forest Score: 0.4460220012264998\n",
      "Gradient Boosting Score: 0.4603369350549257\n",
      "Knn Score with ameneties_score: 0.06473755464183428\n",
      "Random Forest Score with amenities_score: 0.573654858125371\n",
      "Gradient Boosting Score with amenities_score: 0.5982833333099977\n",
      "                     AirBnb's Listing Info  \\\n",
      "Regressors Used                              \n",
      "K-Nearest Neighbors               0.037784   \n",
      "Random Forest                     0.446022   \n",
      "Gradient Boosting                 0.460337   \n",
      "\n",
      "                     AirBnb's Listing Info with Amenity Scores  \n",
      "Regressors Used                                                 \n",
      "K-Nearest Neighbors                                   0.064738  \n",
      "Random Forest                                         0.573655  \n",
      "Gradient Boosting                                     0.598283  \n",
      "Found the Best Amenity Scored Listing's nearby amenities\n",
      "Found the Best Review Scored Listing's nearby amenities\n",
      "Found the Best Valued Listing's nearby amenities\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8959a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_data, amenities_data, user_input1 = read_data()\n",
    "\n",
    "accommodates_input, room_input, price_range_input, exact = handle_input(user_input1)\n",
    "\n",
    "amenities_required = ['restaurant', 'fast_food', 'cafe','bank','atm','pharmacy','bicycle_rental','fuel','pub','bar','car_sharing','car_rental','clinic','doctors','hospital','ice_cream','fountain','theatre','police','bus_station']\n",
    "amenities_data_clean = clean_amenities_data(amenities_data, amenities_required)\n",
    "listings_data_clean = clean_listings_data(listings_data, accommodates_input, room_input, price_range_input, exact, amenities_data_clean)\n",
    "\n",
    "# ML Trials\n",
    "[knn_sc, knn_A_sc, rf_sc, rf_A_sc, gb_sc, gb_A_sc] = run_ml(clean_data_ML(listings_data), amenities_data_clean)\n",
    "ML_RES = [[knn_sc,knn_A_sc], \n",
    "          [rf_sc, rf_A_sc], \n",
    "          [gb_sc,gb_A_sc]]\n",
    "ML_df = pd.DataFrame(ML_RES, \n",
    "                     columns=[\"AirBnb's Listing Info\", \"AirBnb's Listing Info with Amenity Scores\"], \n",
    "                     index=['K-Nearest Neighbors','Random Forest','Gradient Boosting'])\n",
    "ML_df.index.name = \"Regressors Used\"\n",
    "print(ML_df)\n",
    "\n",
    "listings_data_clean=listings_data_clean.reset_index(drop=True)\n",
    "sorted_output = generate_output(listings_data_clean)\n",
    "\n",
    "# outputting csv files accordingly\n",
    "for i in range(len(sorted_output)):\n",
    "    if sorted_output['result'].iloc[i] == \"Best Amenity Scored\":\n",
    "        data_withinA = find_amenties_around_top_listings(sorted_output, amenities_data_clean, i)\n",
    "        data_withinA.index.name = \"Best Amenity Scored\"\n",
    "        data_withinA.to_csv('Best_Amenity_Scored_Listing_nearbyAmenities.csv',na_rep='(missing)')\n",
    "        print(\"Found the Best Amenity Scored Listing's nearby amenities\")\n",
    "        \n",
    "    if sorted_output['result'].iloc[i] == \"Best Scored\":\n",
    "        data_withinS = find_amenties_around_top_listings(sorted_output, amenities_data_clean, i)\n",
    "        data_withinS.index.name = \"Best Scored\"\n",
    "        data_withinS.to_csv('Best_Reviewd_Scored_Listing_nearbyAmenities.csv',na_rep='(missing)')\n",
    "        print(\"Found the Best Review Scored Listing's nearby amenities\")\n",
    "        \n",
    "    if sorted_output['result'].iloc[i] == \"Best Valued\":\n",
    "        data_withinP = find_amenties_around_top_listings(sorted_output, amenities_data_clean, i)\n",
    "        data_withinA.index.name = \"Best Valued\"\n",
    "        data_withinA.to_csv('Best_Valued_Listing_nearbyAmenities.csv',na_rep='(missing)')\n",
    "        print(\"Found the Best Valued Listing's nearby amenities\")\n",
    "        \n",
    "TOP3_OUT = sorted_output.to_csv(\"Top3_Filtered_ABNB_Listings.csv\",na_rep='(missing)')\n",
    "TOTAL_OUT = listings_data_clean.to_csv(\"Total_Filtered_ABNB_Listings.csv\",na_rep='(missing)')\n",
    "ML_OUT = ML_df.to_csv(\"ML_Price_Prediction.csv\",na_rep='(missing)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ba1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_range = [float(s) for s in re.findall('[0-9]+', price_range_input)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8973eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_RES = [[knn_sc,knn_A_sc], \n",
    "          [rf_sc, rf_A_sc], \n",
    "          [gb_sc,gb_A_sc]]\n",
    "ML_df = pd.DataFrame(ML_RES, \n",
    "                     columns=[\"AirBnb's Listing Info\", \"AirBnb's Listing Info with Amenity Scores\"], \n",
    "                     index=['K-Nearest Neighbors','Random Forest','Gradient Boosting'])\n",
    "ML_df.index.name = \"Regressors Used\"\n",
    "ML_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d86a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dedce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(listings_data_clean):\n",
    "    \n",
    "    # sort by price in ascending order\n",
    "    listings_by_price = listings_data_clean.sort_values(by=\"price\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    # sort by review_scores_values in descending order, drop na scores(?)\n",
    "    listings_by_rscore = listings_data_clean.sort_values(['review_scores_value'], ascending=False).dropna().reset_index(drop=True)\n",
    "\n",
    "    # sort by amenities_score in descending order, drop na scores(?)\n",
    "    listings_by_ascore = listings_data_clean.sort_values(['amenities_score'], ascending=False).dropna().reset_index(drop=True)\n",
    "    \n",
    "    # output lowest_price listing, highest scored listing to another dataframe\n",
    "    x = listings_by_rscore.head(1)\n",
    "    x[\"result\"] = \"Best Scored\"    \n",
    "    cols = list(x.columns)\n",
    "    cols = [cols[-1]]+cols[:-1]\n",
    "    x = x[cols]\n",
    "\n",
    "    y = listings_by_price.head(1)\n",
    "    y[\"result\"] = \"Best Valued\"\n",
    "    cols = list(y.columns)\n",
    "    cols = [cols[-1]]+cols[:-1]\n",
    "    y = y[cols]\n",
    "\n",
    "    z = listings_by_ascore.head(1)\n",
    "    z[\"result\"] = \"Best Amenity Scored\"\n",
    "    cols = list(z.columns)\n",
    "    cols = [cols[-1]]+cols[:-1]\n",
    "    z = z[cols]\n",
    "\n",
    "    sorted_output = pd.concat([z, x, y], axis=0, ignore_index=True)\n",
    "#     print(sorted_output)\n",
    "\n",
    "\n",
    "    # display amenities distance/types around the selected listing \n",
    "    # for the first option example:\n",
    "    \n",
    "    \n",
    "    return sorted_output\n",
    "\n",
    "def find_amenties_around_top_listings(sorted_output, amenities_data_clean, i):\n",
    "    amen_output = amenities_data_clean.copy()\n",
    "    lon = sorted_output.iloc[i,7] # lon from utput listing \n",
    "    lat = sorted_output.iloc[i,6] # lat\n",
    "    distance = haversine_distance(amen_output, lon, lat)\n",
    "    amen_output['distance'] = distance\n",
    "    data_withinR = amen_output.loc[amen_output['distance'] < 1000].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    return data_withinR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_output = generate_output(listings_data_clean)\n",
    "for i in range(len(sorted_output)):\n",
    "    \n",
    "    if sorted_output['result'].iloc[i] == \"Best Amenity Scored\":\n",
    "        data_withinA = find_amenties_around_top_listings(sorted_output, amenities_data_clean, i)\n",
    "        data_withinA.index.name = \"Best Amenity Scored\"\n",
    "        data_withinA.to_csv('Best_Amenity_Scored_Listing_nearbyAmenities.csv',na_rep='(missing)')\n",
    "        print(\"Best Amenity Scored Listing's Amenities\")\n",
    "        \n",
    "    if sorted_output['result'].iloc[i] == \"Best Scored\":\n",
    "        data_withinS = find_amenties_around_top_listings(sorted_output, amenities_data_clean, i)\n",
    "        data_withinS.index.name = \"Best Scored\"\n",
    "        print(\"Best Review Scored Listing's Amenities\")\n",
    "        data_withinS.to_csv('Best_Reviewd_Scored_Listing_nearbyAmenities.csv',na_rep='(missing)')\n",
    "\n",
    "    if sorted_output['result'].iloc[i] == \"Best Valued\":\n",
    "        data_withinP = find_amenties_around_top_listings(sorted_output, amenities_data_clean, i)\n",
    "        data_withinA.index.name = \"Best Valued\"\n",
    "        print(\"Best Valued Listing's Amenities\")\n",
    "        data_withinA.to_csv('Best_Valued_Listing_nearbyAmenities.csv',na_rep='(missing)')\n",
    "        \n",
    "TOP3_OUT = sorted_output.to_csv(\"Top3_ABNB_Listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10862f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_output['result'].iloc[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_output.iloc[1,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e86bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_output = generate_output(listings_data_clean)\n",
    "\n",
    "listings_data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_output.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53273aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38978c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
